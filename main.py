import os
import json
import uvicorn
import re
import time
import logging
import random
from datetime import datetime, date
from fastapi import FastAPI, Request
from fastapi.templating import Jinja2Templates
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from langchain_groq import ChatGroq
from duckduckgo_search import DDGS 
import wikipedia
import pandas as pd
import plotly.express as px
import plotly.utils
from collections import Counter

# --- CONFIGURATION ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("NewsWeave-Supreme")

# SAFETY & DISCLAIMER CONFIGURATION
DISCLAIMER_HTML = """
<div style="background: rgba(255, 165, 0, 0.15); border-left: 4px solid #ffaa00; padding: 15px; margin-bottom: 20px; border-radius: 4px; font-size: 0.9rem; color: #ffcc80;">
    <i class="fas fa-exclamation-triangle"></i> <strong>EDUCATIONAL PURPOSE ONLY:</strong> 
    This report was generated by an Autonomous AI Agent. Content is for learning and research purposes only. 
    Real-world data should be verified against primary sources. The creators assume no liability for critical decisions made based on this output.
</div>
"""

INTERNAL_API_KEY = os.environ.get("GROQ_API_KEY")

app = FastAPI()
os.makedirs("static", exist_ok=True)
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# --- PERSISTENCE DB ---
DATA_FILE = "data/stats.json"
os.makedirs("data", exist_ok=True)

def load_stats():
    default = {"prompts_today": 0, "total_prompts": 0, "total_likes": 2450, "date": str(date.today())}
    if not os.path.exists(DATA_FILE): return default
    try:
        with open(DATA_FILE, "r") as f:
            data = json.load(f)
            if data.get("date") != str(date.today()):
                data["prompts_today"] = 0
                data["date"] = str(date.today())
            return data
    except: return default

def save_stats(data):
    with open(DATA_FILE, "w") as f:
        json.dump(data, f)

# --- GLOBAL REGION MAP ---
REGION_MAP = {
    "Global": "wt-wt", "USA": "us-en", "India": "in-en", "UK": "uk-en",
    "China": "cn-zh", "Japan": "jp-jp", "Germany": "de-de", "France": "fr-fr",
    "Russia": "ru-ru", "Brazil": "br-pt", "Canada": "ca-en", "Australia": "au-en"
}

class SearchRequest(BaseModel):
    topic: str
    region: str
    mode: str

# ==========================================
# üß† SWARM INTELLIGENCE CORE (v31 - FIXED)
# ==========================================

class SwarmCommander:
    def __init__(self):
        # Fallback if API key missing
        if not INTERNAL_API_KEY:
             logger.warning("GROQ API KEY MISSING. AI Text generation will fail.")
             self.llm = None
        else:
             self.llm = ChatGroq(temperature=0.0, model_name="llama-3.3-70b-versatile", api_key=INTERNAL_API_KEY)
        
        self.date_str = datetime.now().strftime("%B %d, %Y")
        self.logs = []

    def log(self, agent, message):
        timestamp = datetime.now().strftime("%H:%M:%S")
        entry = f"[{timestamp}] <b>[{agent}]</b> {message}"
        self.logs.append(entry)
        print(entry)

    def _hunter_agent(self, topic, region_code, mode):
        """
        FIXED HUNTER: Uses retries and smart fallbacks to avoid 'Data Void'.
        """
        self.log("HUNTER", f"Initiating multi-vector sweep for: {topic}")
        
        # Strategy Logic
        strategies = []
        if mode == "Fact Check": strategies = [f"{topic} verified fact check", f"is {topic} true or hoax", f"{topic} official statement"]
        elif mode == "Market Analysis": strategies = [f"{topic} revenue statistics {datetime.now().year}", f"{topic} market share data", f"{topic} stock performance"]
        elif mode == "Catalog": strategies = [f"list of {topic}", f"examples of {topic}", f"types of {topic}"]
        else: strategies = [f"{topic} news", f"{topic} detailed analysis", f"{topic} history"]
        
        vault = ""
        success_count = 0

        # Primary Vector: Web/News Search
        with DDGS() as ddgs:
            for q in strategies:
                if success_count >= 3: break # Don't over-query
                try:
                    # Slow down to avoid 429 Rate Limit
                    time.sleep(1) 
                    results = list(ddgs.text(q, region=region_code, backend="lite", max_results=4))
                    if results:
                        success_count += 1
                        for r in results: 
                            vault += f"SOURCE: {r['title']}\nLINK: {r['href']}\nDATA: {r['body']}\n\n"
                except Exception as e:
                    self.log("HUNTER", f"Vector '{q}' blocked: {e}")

        # Fallback Vector: Wikipedia (Smart Keyword Search)
        if len(vault) < 500:
            self.log("HUNTER", "Web data scarce. Engaging Deep-Archive Protocol (Wikipedia).")
            try:
                # Search for keywords instead of full sentence to get hits
                keywords = topic.replace("list of", "").replace("revenue", "").strip()
                page = wikipedia.summary(keywords, sentences=10)
                vault += f"ENCYCLOPEDIA DATA: {page}\n\n"
            except: 
                self.log("HUNTER", "Encyclopedia Protocol returned null.")
        
        return vault

    def _vision_agent(self, topic, region_code, context):
        """
        FIXED VISION: Filters out AI slop, returns verified photo objects.
        """
        self.log("VISION", "Scanning for forensic visual evidence...")
        gallery = []
        seen = set()
        blacklist = ["ai generated", "cartoon", "vector", "drawing", "clipart", "logo", "icon", "render", "illustration"]
        
        # Smart Query Generation
        query = f"{topic} real photo"
        if "wreckage" in topic.lower(): query = f"{topic} site photo"
        if "revenue" in topic.lower(): query = f"{topic} chart graph"

        try:
            with DDGS() as ddgs:
                results = list(ddgs.images(query, region=region_code, max_results=30))
                for r in results:
                    if len(gallery) >= 50: break
                    t = r.get('title', '').lower()
                    src = r.get('image', '')
                    
                    if src not in seen and not any(b in t for b in blacklist):
                        gallery.append({"src": src, "title": r['title']})
                        seen.add(src)
        except: pass
        
        self.log("VISION", f"Secured {len(gallery)} verified visual assets.")
        return gallery

    def _analyst_agent(self, text):
        """
        FIXED ANALYST: Fixes the 'Float Year' bug (2025.5) and forces Integers.
        """
        self.log("ANALYST", "Parsing data for predictive modeling...")
        try:
            years = re.findall(r'\b(20\d{2})\b', text)
            numbers = re.findall(r'\b(\d{1,3}(?:,\d{3})*(?:\.\d+)?)\b', text)
            
            if len(years) > 1 and len(numbers) > 1:
                clean_years, clean_nums = [], []
                limit = min(len(years), len(numbers))

                for i in range(limit):
                    try:
                        y = int(years[i]) # Force Integer
                        v = float(numbers[i].replace(',', ''))
                        # Filter out year-like numbers from the values column
                        if 1900 < v < 2100: continue 
                        clean_years.append(y); clean_nums.append(v)
                    except: pass
                
                if clean_years:
                    df = pd.DataFrame({"Year": clean_years, "Value": clean_nums})
                    # Sort by year to prevent zig-zag charts
                    df = df.sort_values(by="Year") 
                    
                    # Create Chart
                    fig = px.scatter(df, x="Year", y="Value", title="Trend Analysis (Projected)", 
                                     trendline="ols" if len(df) > 3 else None, 
                                     template="plotly_dark")
                    
                    # FIX: Force X-Axis to use Integer Ticks (No 2025.5)
                    fig.update_layout(xaxis=dict(dtick=1))
                    
                    return json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)
        except Exception as e: 
            self.log("ANALYST", f"Charting failed: {e}")
        return None

    def execute_mission(self, topic, region, mode):
        self.logs = [] # Reset logs
        self.log("COMMANDER", f"Mission Initialized: {topic} [{mode}]")
        
        # 1. Update Stats
        s = load_stats()
        s["prompts_today"] += 1; s["total_prompts"] += 1
        save_stats(s)

        # 2. Hunter Phase
        region_code = REGION_MAP.get(region, "wt-wt")
        context = self._hunter_agent(topic, region_code, mode)
        images = self._vision_agent(topic, region_code, context)

        # 3. FIX: Handle "Data Void" but "Visual Success"
        if not context and not images:
             return f"{DISCLAIMER_HTML}<h3>‚ö†Ô∏è Mission Failed</h3><p>Data Void detected. No reliable sources found.</p>", [], None, self.logs
        
        visual_note = ""
        if not context and images:
            visual_note = f"CRITICAL NOTE: Text search failed, but {len(images)} visual records were found. Analyze the topic based on general knowledge and reference the Visual Evidence panel. Do not claim data is missing."

        # 4. Editor Phase (LLM Synthesis)
        self.log("EDITOR", "Synthesizing Intelligence Dossier...")
        
        structure = ""
        if mode == "Catalog": structure = "CATALOG MODE: List EVERY item found. Bullet points."
        elif mode == "Fact Check": structure = "VERDICT MODE: State VERIFIED or DEBUNKED immediately."
        else: structure = "Structure: <h3>Executive Verdict</h3>, <h3>Deep Dive Analysis</h3>, <h3>Key Evidence</h3>, <h3>Strategic Outlook</h3>."

        prompt = f"""
        You are NewsWeave Supreme. TOPIC: {topic} | MODE: {mode} | REGION: {region}
        
        INTELLIGENCE VAULT:
        {context}
        
        {visual_note}
        
        INSTRUCTIONS:
        1. {structure}
        2. **Citations:** Use specific citations like [1], [2] where possible.
        3. **No Hallucinations:** If data is missing, admit it.
        4. Use HTML tags (h3, p, ul, li).
        """
        
        try: 
            if self.llm:
                report_body = self.llm.invoke(prompt).content
            else:
                report_body = "<p>System Offline: API Key Missing.</p>"
        except Exception as e: report_body = f"AI Error: {e}"

        # FIX: Inject Disclaimer
        final_report = DISCLAIMER_HTML + report_body

        # 5. Analyst Phase
        chart = self._analyst_agent(final_report)
        
        self.log("COMMANDER", "Mission Complete.")
        return final_report, images, chart, self.logs

agent = SwarmCommander()

# ==========================================
# üåê API ROUTES
# ==========================================

@app.get("/")
async def serve_interface(request: Request):
    stats = load_stats()
    return templates.TemplateResponse("index.html", {"request": request, "total_likes": stats["total_likes"]})

@app.post("/analyze")
async def analyze_endpoint(request: SearchRequest):
    report, images, chart, logs = agent.execute_mission(request.topic, request.region, request.mode)
    return JSONResponse(content={"report": report, "images": images, "chart": chart, "logs": logs})

@app.post("/like")
async def like_endpoint():
    s = load_stats()
    s["total_likes"] += 1
    save_stats(s)
    return JSONResponse(content={"new_count": s["total_likes"]})

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
